{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this every time you open the spreadsheet\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import Counter\n",
    "import lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally huge tree tree monday.. monday.. house house anymore structural damage damage storm..still storm..still damage damage done..\n",
      "==========\n",
      "['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__getitem__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '__weakref__', '_bigramList', '_featureSet', 'category', 'idx', 'need_or_resource', 'orig', 'tokenList', 'tokenSet']\n",
      "==========\n",
      "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__delslice__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "==========\n",
      "1120\n"
     ]
    }
   ],
   "source": [
    "# Load the data.\n",
    "# This function returns tweets and test_tweets, both lists of tweets\n",
    "tweets, test_tweets = lib.read_data()\n",
    "i = 1\n",
    "from pprint import pprint\n",
    "pprint(tweets[1])\n",
    "\n",
    "def dump(obj):\n",
    "  for attr in dir(obj):\n",
    "    print \"obj.%s = %s\" % (attr, getattr(obj, attr))\n",
    "\n",
    "# dump(tweets[1])\n",
    "# print \"==========\"\n",
    "# print vars(tweets[1])\n",
    "print \"==========\"\n",
    "print dir(tweets[1])\n",
    "# print \"==========\"\n",
    "# print getattr(tweets[1], \"__dict__\")\n",
    "print \"==========\"\n",
    "print dir(tweets)\n",
    "print \"==========\"\n",
    "print len(tweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learn a Naive Bayes classifier\n",
    "\n",
    "To construct our Naive Bayes classifier, we first need to calculate two things:\n",
    "\n",
    "### Prior probabilities of categories\n",
    "We need to calculate $P(C_i)$ for each category $C_i \\in \\{\\text{Energy}, \\text{Food}, \\text{Medical}, \\text{Water}, \\text{None}\\}$. \n",
    "\n",
    "We estimate $P(C_i)$ by $\\frac{\\text{# tweets about }C_i}{\\text{# tweets}}$\n",
    "\n",
    "### Conditional probabilities of tokens\n",
    "For each token (i.e. word) $x_j$ and each category $C_i$, we need to calculate $P(x_j|C_i)$.\n",
    "\n",
    "We estimate $P(x_j|C_i) = \\frac{P(x_j \\text{ and } C_i)}{P(C_i)}$ by $\\frac{\\text{# tweets about }C_i \\text{ containing }x_j}{\\text{# tweets about }C_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "528\n",
      "---\n",
      "Class Food has prior probability 0.47\n",
      "101\n",
      "---\n",
      "Class Water has prior probability 0.09\n",
      "138\n",
      "---\n",
      "Class Energy has prior probability 0.12\n",
      "44\n",
      "---\n",
      "Class Medical has prior probability 0.04\n",
      "309\n",
      "---\n",
      "Class None has prior probability 0.28\n",
      "======= token_probs_food ========\n",
      "Counter()\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1, step-by-step version (challenge version is below).\n",
    "\n",
    "# The function below has two arguments: a list of tweets, and a category c\n",
    "# which is a string equal to one of \"Energy\", \"Food\", \"Medical\", \"Water\", \"None\".\n",
    "# The function should calculate the two things described above.\n",
    "# Fill in the blanks.\n",
    "print \"===============\"\n",
    "\n",
    "\n",
    "def calc_probs(tweets, c):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        c: a string representing a category; one of \"Energy\", \"Food\", \"Medical\", \"Water\", \"None\". \n",
    "    Returns:\n",
    "        prob_c: the prior probability of category c\n",
    "        token_probs: a Counter mapping each token to P(token|category c)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Calculate the total number of tweets\n",
    "    num_tweets = len(tweets)\n",
    "\n",
    "    \n",
    "    # Step 2: Calculate the number of tweets that are about category c.\n",
    "    # Save the answer to a variable called num_tweets_about_c.\n",
    "    # Remember c is a string, and you can get the category of a tweet via tweet.category\n",
    "    num_tweets_about_c = 0\n",
    "    for t in tweets :\n",
    "        if t.category == c :\n",
    "            num_tweets_about_c += 1\n",
    "    \n",
    "    print num_tweets_about_c\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Step 3: Calculate the probability of category c using the answers from Steps 1 and 2.\n",
    "    # Hint: be careful when you divide two integers!\n",
    "    prob_c = float(num_tweets_about_c) / num_tweets\n",
    "    \n",
    "    \n",
    "    # Step 4: Create an empty Counter called token_counts.\n",
    "    # (We will use it to map each token to the number of category-c tweets containing that token.)\n",
    "    token_counts = Counter()\n",
    "    \n",
    "    \n",
    "    # Step 5 (tricky): Use a for-loop to iterate over the list of tweets.\n",
    "    # Use an if-statement to check whether the tweet is in category c.\n",
    "    # If it is, iterate over the tokens of the tweet (which you can access via tweet.tokenSet) using a for-loop.\n",
    "    # For each token, increment its count in token_counts.\n",
    "\n",
    "    print \"---\"\n",
    "    \n",
    "    \n",
    "    # Step 6: Create an empty Counter called token_probs.\n",
    "    # (We will use it to map each token to P(token | category c), \n",
    "    # i.e. the fraction of all category-c tweets that contain the token)\n",
    "    token_probs = Counter()\n",
    "    \n",
    "    \n",
    "    # Step 7: Now fill token_probs.\n",
    "    # For each token->count in token_counts, you want to add token->fraction to token_probs.\n",
    "    # Use a for-loop over token_counts. \n",
    "    # Remember that when you iterate over a dictionary/Counter, you access the keys.\n",
    "    # You'll need to use the variable num_tweets_about_c.\n",
    "    # Be careful when you divide integers!\n",
    "    for t in tweets :\n",
    "        if t.category == c :\n",
    "            for w in t.tokenList :\n",
    "                token_counts.update({w: 1})\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    print \"Class %s has prior probability %.2f\" % (c, prob_c)    \n",
    "    return prob_c, token_probs\n",
    "\n",
    "\n",
    "\n",
    "prob_food, token_probs_food = calc_probs(tweets, \"Food\")\n",
    "prob_water, token_probs_water = calc_probs(tweets, \"Water\")\n",
    "prob_energy, token_probs_energy = calc_probs(tweets, \"Energy\")\n",
    "prob_medical, token_probs_medical = calc_probs(tweets, \"Medical\")\n",
    "prob_none, token_probs_none = calc_probs(tweets, \"None\")\n",
    "\n",
    "print \"======= token_probs_food ========\"\n",
    "print token_probs_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'prob_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bc22ffede7ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mprob_food\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_probs_food\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Food\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mprob_water\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_probs_water\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Water\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprob_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_probs_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_probs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Energy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-bc22ffede7ad>\u001b[0m in \u001b[0;36mcalc_probs\u001b[0;34m(tweets, c)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m##### YOUR CODE ENDS HERE ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Class %s has prior probability %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m##### OPTIONAL EXERCISE STARTS HERE ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'prob_c' is not defined"
     ]
    }
   ],
   "source": [
    "# Exercise 1, challenge version (step-by-step version is above).\n",
    "\n",
    "# Implement the function!\n",
    "\n",
    "# Reminders:\n",
    "#   tweet.category gets you the category of a tweet (as a string)\n",
    "#   tweet.tokenSet gets you the set of tokens in a tweet (lowercased).\n",
    "#     You can iterate over a set just like a list using a for-loop.\n",
    "\n",
    "\n",
    "def calc_probs(tweets, c):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        c: a string representing a category; one of \"Energy\", \"Food\", \"Medical\", \"Water\", \"None\". \n",
    "    Returns:\n",
    "        prob_c: the prior probability of category c\n",
    "        token_probs: a Counter mapping each token to P(token|category c)\n",
    "    \"\"\"\n",
    "    \n",
    "    ##### YOUR CODE STARTS HERE ####\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### YOUR CODE ENDS HERE ####\n",
    "            \n",
    "    print \"Class %s has prior probability %.2f\" % (c, prob_c)\n",
    "    \n",
    "    ##### OPTIONAL EXERCISE STARTS HERE ####\n",
    "    \n",
    "    # Write some code to nicely-print the top most common tokens for this category.\n",
    "    # Note that token_probs.most_common(10) gives you the 10 most common tokens in the counter,\n",
    "    # as a list of (token, probability) pairs. This is another convenient feature of Counters!\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### OPTIONAL EXERCISE ENDS HERE ####\n",
    "\n",
    "    return prob_c, token_probs\n",
    "\n",
    "\n",
    "prob_food, token_probs_food = calc_probs(tweets, \"Food\")\n",
    "prob_water, token_probs_water = calc_probs(tweets, \"Water\")\n",
    "prob_energy, token_probs_energy = calc_probs(tweets, \"Energy\")\n",
    "prob_medical, token_probs_medical = calc_probs(tweets, \"Medical\")\n",
    "prob_none, token_probs_none = calc_probs(tweets, \"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### See what your model has learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_probs_food' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c26b5b90dde3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For each category c, print out the tokens that maximize P(c|token)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtoken_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Food'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_probs_food\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Water'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_probs_water\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Energy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_probs_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Medical'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_probs_medical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'None'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_probs_none\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprior_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Food'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob_food\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Water'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob_water\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Energy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Medical'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob_medical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob_none\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_discriminative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_probs_food' is not defined"
     ]
    }
   ],
   "source": [
    "# For each category c, print out the tokens that maximize P(c|token)\n",
    "\n",
    "token_probs = {'Food': token_probs_food, 'Water': token_probs_water, 'Energy': token_probs_energy, 'Medical': token_probs_medical,'None': token_probs_none}\n",
    "prior_probs = {'Food': prob_food, 'Water': prob_water, 'Energy': prob_energy, 'Medical': prob_medical, 'None': prob_none}\n",
    "lib.most_discriminative(tweets, token_probs, prior_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Naive Bayes classifier\n",
    "\n",
    "Now we've calculated $P(C_i)$ and $P(x_j|C_i)$, we can classify any tweet!\n",
    "\n",
    "Given a tweet which is a set of tokens $\\{x_1,...,x_n\\}$, the posterior probability of each category $C_i$ is\n",
    "\n",
    "$P(C_i | x_1,...,x_n) \\propto P(C_i) \\times P(x_1|C_i) \\times P(x_2|C_i) ... \\times P(x_n|C_i)$\n",
    "\n",
    "We just need to calculate this for each category then determine which is largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2. \n",
    "\n",
    "# Complete this function that calculates the posterior probability of P(c|tweet).\n",
    "\n",
    "def get_posterior_prob(tweet, prob_c, token_probs):\n",
    "    \"\"\"Calculate the posterior P(c|tweet). \n",
    "    (Actually, calculate something proportional to it).\n",
    "    \n",
    "    Inputs:\n",
    "        tweet: a tweet\n",
    "        prob_c: the prior probability of category c\n",
    "        token_probs: a Counter mapping each token P(token|c)\n",
    "    Return:\n",
    "        The posterior P(c|tweet).\n",
    "    \"\"\"\n",
    "\n",
    "    ##### YOUR CODE STARTS HERE #####\n",
    "    \n",
    "    # Hint: first set posterior to prob_c, then use a for-loop over tweet.tokenSet\n",
    "    # to repeatedly multiply posterior by P(token|c)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    ##### YOUR CODE ENDS HERE #####\n",
    "    \n",
    "    return posterior\n",
    "\n",
    "\n",
    "\n",
    "# Now you've written the function, look at the output for P(Energy|\"No power in Riverdale\").\n",
    "# What's gone wrong? \n",
    "# Try editing your function above to print out each token and token_probs[token].\n",
    "# Can you see what went wrong? How might you fix it?\n",
    "\n",
    "riverdale_tweet = lib.Tweet(\"No power in Riverdale\", \"Energy\", \"need\")\n",
    "print \"P(Energy|'No power in Riverdale') = \", get_posterior_prob(riverdale_tweet, prob_energy, token_probs_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell defines the classification function, that takes a tweet \n",
    "# and decides which category is most likely using the posteriors you just calculated.\n",
    "\n",
    "\n",
    "# OPTIONAL EXERCISE (come back to it once you've reached the end of the notebook).\n",
    "# Rewrite this function to be less repetitive i.e. don't repeat things 5 times.\n",
    "# There are several possible solutions; you might want to use lists or dictionaries.\n",
    "# You might also want to rewrite the earlier code that computed prob_food, token_probs_food etc.\n",
    "\n",
    "\n",
    "def classify_nb(tweet):\n",
    "    \"\"\"Classifies a tweet. Calculates the posterior P(c|tweet) for each category c, \n",
    "    and returns the category with largest posterior.\n",
    "    Input:\n",
    "        tweet\n",
    "    Output:\n",
    "        string equal to most-likely category for this tweet\n",
    "    \"\"\"\n",
    "    posterior_food_prob = get_posterior_prob(tweet, prob_food, token_probs_food)\n",
    "    posterior_water_prob = get_posterior_prob(tweet, prob_water, token_probs_water)\n",
    "    posterior_energy_prob = get_posterior_prob(tweet, prob_energy, token_probs_energy)\n",
    "    posterior_medical_prob = get_posterior_prob(tweet, prob_medical, token_probs_medical)\n",
    "    posterior_none_prob = get_posterior_prob(tweet, prob_none, token_probs_none)\n",
    "    \n",
    "    max_posterior = max([posterior_food_prob, posterior_water_prob, posterior_energy_prob, posterior_medical_prob, posterior_none_prob])\n",
    "    if posterior_food_prob == max_posterior:\n",
    "        return 'Food'\n",
    "    elif posterior_water_prob == max_posterior:\n",
    "        return 'Water'\n",
    "    elif posterior_energy_prob == max_posterior:\n",
    "        return 'Energy'\n",
    "    elif posterior_medical_prob == max_posterior:\n",
    "        return 'Medical'\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classify_nb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ad1c580d4a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compare true labels and predicted labels in a table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassify_nb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_tweets\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# a list of (tweet, prediction) pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classify_nb' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare true labels and predicted labels in a table\n",
    "\n",
    "predictions = [(tweet, classify_nb(tweet)) for tweet in test_tweets] # a list of (tweet, prediction) pairs\n",
    "lib.show_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get average F1 score for the test set\n",
    "\n",
    "predictions = [(tweet, classify_nb(tweet)) for tweet in test_tweets] # maps each test tweet to its predicted label\n",
    "lib.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get average F1 score for the TRAINING set.\n",
    "# Compare with average F1 for test set above. What's the reason for the difference?\n",
    "\n",
    "trainset_predictions = [(tweet, classify_nb(tweet)) for tweet in tweets] # maps each training tweet to its predicted label\n",
    "lib.evaluate(trainset_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lib.show_confusion_matrix(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
